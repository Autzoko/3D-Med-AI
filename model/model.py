"""
Complete SegMamba + Mask2Former Model
æ•´åˆäº†backbone, pixel decoder, å’Œ transformer decoderçš„å®Œæ•´æ¨¡å‹

Author: Based on Mask2Former (CVPR 2022) and SegMamba (MICCAI 2024)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional

# å¯¼å…¥æˆ‘ä»¬çš„ç»„ä»¶
from model.backbone.segmamba_backbone_2d import (
    SegMambaBackbone2D,
    segmamba_backbone_tiny,
    segmamba_backbone_small,
    segmamba_backbone_base,
)
from model.detector.pixel_decoder import SimpleFPNDecoder, BasePixelDecoder
from model.detector.mask2former_decoder import Mask2FormerTransformerDecoder


class SegMambaMask2Former(nn.Module):
    """
    å®Œæ•´çš„SegMamba + Mask2Formeræ¨¡å‹
    
    æ¶æ„æµç¨‹:
        è¾“å…¥å›¾åƒ (B, C, H, W)
            â†“
        SegMamba Backbone â†’ æå–å¤šå°ºåº¦ç‰¹å¾
            â†“
        Pixel Decoder (FPN) â†’ ç”Ÿæˆmask featureså’Œmulti-scale features
            â†“
        Mask2Former Decoder â†’ Query-basedé¢„æµ‹
            â†“
        è¾“å‡º: {pred_logits, pred_masks, aux_outputs}
    
    é€‚ç”¨åœºæ™¯:
        - åŒ»å­¦è¶…å£°å›¾åƒåˆ†å‰²
        - åŸŸé€‚åº”ä»»åŠ¡
        - å°‘æ ·æœ¬å­¦ä¹ 
        - å®ä¾‹/è¯­ä¹‰åˆ†å‰²
    """
    
    def __init__(
        self,
        # Backboneé…ç½®
        backbone_name: str = 'small',  # 'tiny', 'small', 'base'
        in_chans: int = 1,
        # Pixel decoderé…ç½®
        pixel_decoder_name: str = 'simple_fpn',  # 'simple_fpn' or 'base_fpn'
        conv_dim: int = 256,
        mask_dim: int = 256,
        # Transformer decoderé…ç½®
        hidden_dim: int = 256,
        num_queries: int = 30,
        nheads: int = 8,
        dim_feedforward: int = 2048,
        dec_layers: int = 6,
        pre_norm: bool = False,
        # ä»»åŠ¡é…ç½®
        num_classes: int = 2,  # åˆ†ç±»æ•°ï¼ˆä¸åŒ…æ‹¬èƒŒæ™¯ï¼‰
        enforce_input_project: bool = False,
    ):
        """
        Args:
            backbone_name: SegMamba backboneå¤§å° ('tiny', 'small', 'base')
            in_chans: è¾“å…¥é€šé“æ•° (1=ç°åº¦, 3=RGB)
            pixel_decoder_name: pixel decoderç±»å‹
            conv_dim: pixel decoderä¸­é—´é€šé“æ•°
            mask_dim: maskç‰¹å¾ç»´åº¦
            hidden_dim: transformeréšè—å±‚ç»´åº¦
            num_queries: object queriesæ•°é‡ (æ¨è: 20-30 for medical imaging)
            nheads: attention headsæ•°é‡
            dim_feedforward: FFNç»´åº¦
            dec_layers: decoderå±‚æ•°
            pre_norm: æ˜¯å¦ä½¿ç”¨pre-normalization
            num_classes: åˆ†å‰²ç±»åˆ«æ•°ï¼ˆä¸åŒ…æ‹¬èƒŒæ™¯ç±»ï¼‰
            enforce_input_project: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨input projection
        """
        super().__init__()
        
        self.num_classes = num_classes
        self.num_queries = num_queries
        self.backbone_name = backbone_name
        
        # ==================== 1. åˆ›å»ºBackbone ====================
        print(f"[Model] Creating {backbone_name} backbone...")
        
        if backbone_name == 'tiny':
            self.backbone = segmamba_backbone_tiny(
                in_chans=in_chans,
                return_features='all'
            )
            backbone_dims = [48, 96, 192, 384]
        elif backbone_name == 'small':
            self.backbone = segmamba_backbone_small(
                in_chans=in_chans,
                return_features='all'
            )
            backbone_dims = [48, 96, 192, 384]
        elif backbone_name == 'base':
            self.backbone = segmamba_backbone_base(
                in_chans=in_chans,
                return_features='all'
            )
            backbone_dims = [64, 128, 256, 512]
        else:
            raise ValueError(f"Unknown backbone: {backbone_name}")
        
        print(f"  âœ“ Backbone dims: {backbone_dims}")
        
        # ==================== 2. åˆ›å»ºPixel Decoder ====================
        print(f"[Model] Creating {pixel_decoder_name} pixel decoder...")
        
        if pixel_decoder_name == 'simple_fpn':
            self.pixel_decoder = SimpleFPNDecoder(
                in_channels_list=backbone_dims,
                conv_dim=conv_dim,
                mask_dim=mask_dim,
            )
        elif pixel_decoder_name == 'base_fpn':
            self.pixel_decoder = BasePixelDecoder(
                in_channels_list=backbone_dims,
                conv_dim=conv_dim,
                mask_dim=mask_dim,
            )
        else:
            raise ValueError(f"Unknown pixel decoder: {pixel_decoder_name}")
        
        print(f"  âœ“ Pixel decoder: conv_dim={conv_dim}, mask_dim={mask_dim}")
        
        # ==================== 3. åˆ›å»ºMask2Former Decoder ====================
        print(f"[Model] Creating Mask2Former transformer decoder...")
        
        self.transformer_decoder = Mask2FormerTransformerDecoder(
            in_channels=conv_dim,
            mask_classification=True,
            num_classes=num_classes,
            hidden_dim=hidden_dim,
            num_queries=num_queries,
            nheads=nheads,
            dim_feedforward=dim_feedforward,
            dec_layers=dec_layers,
            pre_norm=pre_norm,
            mask_dim=mask_dim,
            enforce_input_project=enforce_input_project,
        )
        
        print(f"  âœ“ Transformer decoder: {num_queries} queries, {dec_layers} layers")
        print(f"[Model] Model created successfully!")
        
    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥å›¾åƒ (B, C, H, W)
            
        Returns:
            å­—å…¸åŒ…å«:
                - pred_logits: (B, Q, num_classes+1) ç±»åˆ«é¢„æµ‹ï¼ˆ+1æ˜¯èƒŒæ™¯ç±»ï¼‰
                - pred_masks: (B, Q, H/4, W/4) maské¢„æµ‹
                - aux_outputs: list of dictsï¼Œä¸­é—´å±‚é¢„æµ‹ï¼ˆç”¨äºdeep supervisionï¼‰
                
        Example:
            >>> model = SegMambaMask2Former(num_classes=2)
            >>> images = torch.randn(4, 1, 256, 256)
            >>> predictions = model(images)
            >>> logits = predictions['pred_logits']  # (4, 30, 3)
            >>> masks = predictions['pred_masks']    # (4, 30, 64, 64)
        """
        # 1. Backbone: æå–å¤šå°ºåº¦ç‰¹å¾
        # Output: [(B,48,H/2,W/2), (B,96,H/4,W/4), (B,192,H/8,W/8), (B,384,H/16,W/16)]
        backbone_features = self.backbone(x)
        
        # 2. Pixel Decoder: ç”Ÿæˆmask featureså’Œmulti-scale features
        # mask_features: (B, mask_dim, H/4, W/4)
        # multi_scale_features: [(B,C,H/32,W/32), (B,C,H/16,W/16), (B,C,H/8,W/8)]
        mask_features, multi_scale_features = self.pixel_decoder(backbone_features)
        
        # 3. Transformer Decoder: Query-basedé¢„æµ‹
        predictions = self.transformer_decoder(multi_scale_features, mask_features)
        
        return predictions
    
    def get_num_layers(self):
        """è·å–decoderå±‚æ•°ï¼ˆç”¨äºdeep supervisionï¼‰"""
        return self.transformer_decoder.num_layers + 1  # +1 for learnable queries
    
    def get_model_info(self) -> Dict:
        """è·å–æ¨¡å‹é…ç½®ä¿¡æ¯"""
        return {
            'backbone': self.backbone_name,
            'num_classes': self.num_classes,
            'num_queries': self.num_queries,
            'num_decoder_layers': self.transformer_decoder.num_layers,
            'hidden_dim': self.transformer_decoder.decoder_norm.normalized_shape[0],
        }


# ============================================================================
# ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºä¸åŒè§„æ¨¡çš„æ¨¡å‹
# ============================================================================

def segmamba_mask2former_tiny(
    num_classes: int = 2,
    num_queries: int = 20,
    in_chans: int = 1,
    **kwargs
) -> SegMambaMask2Former:
    """
    Tinyæ¨¡å‹é…ç½®
    
    é€‚ç”¨åœºæ™¯:
        - å¿«é€Ÿå®éªŒ
        - GPUæ˜¾å­˜å—é™
        - å®æ—¶æ¨ç†
    
    è§„æ ¼:
        - Backbone: SegMamba Tiny (~5M params)
        - Queries: 20
        - Decoder layers: 3
        - æ€»å‚æ•°: ~13M
    """
    return SegMambaMask2Former(
        backbone_name='tiny',
        in_chans=in_chans,
        num_classes=num_classes,
        num_queries=num_queries,
        hidden_dim=256,
        dec_layers=3,
        **kwargs
    )


def segmamba_mask2former_small(
    num_classes: int = 2,
    num_queries: int = 30,
    in_chans: int = 1,
    **kwargs
) -> SegMambaMask2Former:
    """
    Smallæ¨¡å‹é…ç½®ï¼ˆæ¨èç”¨äºåŒ»å­¦å›¾åƒï¼‰
    
    é€‚ç”¨åœºæ™¯:
        - åŒ»å­¦å›¾åƒåˆ†å‰²
        - åŸŸé€‚åº”ä»»åŠ¡
        - å¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡
    
    è§„æ ¼:
        - Backbone: SegMamba Small (~8M params)
        - Queries: 30
        - Decoder layers: 6
        - æ€»å‚æ•°: ~18M
    """
    return SegMambaMask2Former(
        backbone_name='small',
        in_chans=in_chans,
        num_classes=num_classes,
        num_queries=num_queries,
        hidden_dim=256,
        dec_layers=6,
        **kwargs
    )


def segmamba_mask2former_base(
    num_classes: int = 2,
    num_queries: int = 50,
    in_chans: int = 1,
    **kwargs
) -> SegMambaMask2Former:
    """
    Baseæ¨¡å‹é…ç½®
    
    é€‚ç”¨åœºæ™¯:
        - æœ€é«˜æ€§èƒ½éœ€æ±‚
        - å¤§æ•°æ®é›†
        - å¤æ‚åˆ†å‰²ä»»åŠ¡
    
    è§„æ ¼:
        - Backbone: SegMamba Base (~15M params)
        - Queries: 50
        - Decoder layers: 6
        - æ€»å‚æ•°: ~30M
    """
    return SegMambaMask2Former(
        backbone_name='base',
        in_chans=in_chans,
        num_classes=num_classes,
        num_queries=num_queries,
        hidden_dim=256,
        dec_layers=6,
        **kwargs
    )


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    print("\n" + "="*80)
    print("SegMamba + Mask2Former å®Œæ•´æ¨¡å‹æµ‹è¯•")
    print("="*80 + "\n")
    
    # ==================== æµ‹è¯•1: åˆ›å»ºæ¨¡å‹ ====================
    print("[æµ‹è¯• 1] åˆ›å»ºæ¨¡å‹")
    print("-" * 40)
    model = segmamba_mask2former_small(num_classes=2, num_queries=30)
    print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"  æ¨¡å‹ä¿¡æ¯: {model.get_model_info()}\n")
    
    # ==================== æµ‹è¯•2: å‰å‘ä¼ æ’­ ====================
    print("[æµ‹è¯• 2] å‰å‘ä¼ æ’­")
    print("-" * 40)
    # æ¨¡æ‹Ÿè¾“å…¥: 4å¼ 256x256çš„ç°åº¦è¶…å£°å›¾åƒ
    images = torch.randn(4, 1, 256, 256)
    print(f"è¾“å…¥å½¢çŠ¶: {images.shape}")
    
    with torch.no_grad():
        predictions = model(images)
    
    print(f"è¾“å‡º:")
    print(f"  pred_logits: {predictions['pred_logits'].shape}")
    print(f"  pred_masks: {predictions['pred_masks'].shape}")
    print(f"  aux_outputs: {len(predictions['aux_outputs'])} ä¸ªä¸­é—´å±‚é¢„æµ‹")
    print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ\n")
    
    # ==================== æµ‹è¯•3: å‚æ•°ç»Ÿè®¡ ====================
    print("[æµ‹è¯• 3] å‚æ•°ç»Ÿè®¡")
    print("-" * 40)
    
    models = {
        'Tiny': segmamba_mask2former_tiny(),
        'Small': segmamba_mask2former_small(),
        'Base': segmamba_mask2former_base(),
    }
    
    for name, m in models.items():
        total_params = sum(p.numel() for p in m.parameters())
        backbone_params = sum(p.numel() for p in m.backbone.parameters())
        pixel_params = sum(p.numel() for p in m.pixel_decoder.parameters())
        decoder_params = sum(p.numel() for p in m.transformer_decoder.parameters())
        
        print(f"{name:10s}:")
        print(f"  æ€»å‚æ•°: {total_params/1e6:>6.2f}M")
        print(f"  â””â”€ Backbone:  {backbone_params/1e6:>6.2f}M")
        print(f"  â””â”€ Pixel Dec: {pixel_params/1e6:>6.2f}M")
        print(f"  â””â”€ Trans Dec: {decoder_params/1e6:>6.2f}M")
    
    print()
    
    # ==================== æµ‹è¯•4: ä¸åŒè¾“å…¥å°ºå¯¸ ====================
    print("[æµ‹è¯• 4] ä¸åŒè¾“å…¥å°ºå¯¸")
    print("-" * 40)
    
    model = segmamba_mask2former_small(num_classes=2)
    
    for size in [128, 256, 512]:
        x = torch.randn(1, 1, size, size)
        with torch.no_grad():
            out = model(x)
        print(f"è¾“å…¥ {size}x{size} â†’ pred_masks: {out['pred_masks'].shape}")
    
    print(f"âœ“ æ”¯æŒä¸åŒè¾“å…¥å°ºå¯¸\n")
    
    # ==================== æµ‹è¯•5: æå–backboneç‰¹å¾ ====================
    print("[æµ‹è¯• 5] æå–backboneç‰¹å¾ï¼ˆç”¨äºåŸŸé€‚åº”ï¼‰")
    print("-" * 40)
    
    # è¿™å¯¹åŸŸé€‚åº”å¾ˆæœ‰ç”¨
    images = torch.randn(2, 1, 256, 256)
    with torch.no_grad():
        backbone_features = model.backbone(images)
    
    print(f"æå–åˆ° {len(backbone_features)} ä¸ªå°ºåº¦çš„ç‰¹å¾:")
    for i, feat in enumerate(backbone_features):
        print(f"  Stage {i}: {feat.shape}")
    
    print(f"âœ“ å¯ä»¥æ–¹ä¾¿åœ°æå–backboneç‰¹å¾ç”¨äºåŸŸé€‚åº”\n")
    
    # ==================== æµ‹è¯•6: å¤šç±»åˆ«åˆ†å‰² ====================
    print("[æµ‹è¯• 6] å¤šç±»åˆ«åˆ†å‰²")
    print("-" * 40)
    
    # åˆ›å»º5ç±»åˆ†å‰²æ¨¡å‹
    model_multiclass = segmamba_mask2former_small(num_classes=5, num_queries=30)
    x = torch.randn(2, 1, 256, 256)
    
    with torch.no_grad():
        out = model_multiclass(x)
    
    print(f"è¾“å…¥: {x.shape}")
    print(f"pred_logits: {out['pred_logits'].shape}  # 6ç±» = 5ç±» + 1èƒŒæ™¯")
    print(f"pred_masks: {out['pred_masks'].shape}")
    print(f"âœ“ æ”¯æŒå¤šç±»åˆ«åˆ†å‰²\n")
    
    print("="*80)
    print("æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼âœ“")
    print("="*80)
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. å‡†å¤‡æ‚¨çš„æ•°æ®é›†")
    print("  2. å®ç°DataLoader")
    print("  3. å®ç°è®­ç»ƒå¾ªç¯ï¼ˆéœ€è¦Hungarian matchingï¼‰")
    print("  4. å¼€å§‹è®­ç»ƒï¼")
    print()